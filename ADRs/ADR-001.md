# ADR-001: Use of AI for Grading Short Answers in Test 1
Authored by: The Northstars
Date: 2025-02-13

## Status
    [X] Proposed
    []  Accepted
    []  Rejected


## Context
Test 1 includes a mix of autograded and manually graded short answer questions. The current manual grading process for these questions is time-consuming and can lead to inconsistencies in grading. It also isn't fesabile considering the growth. We aim to speed up the grading process and maintain consistency by integrating AI assistance. This decision arises from the need to handle a large volume of student responses efficiently while ensuring high grading standards.

## Decision
We have decided to use AI to assist in grading the short answer questions of Test 1. The AI will grade responses where it can achieve N% certainty (where N would be set by the business). Questions where the AI's confidence falls below this threshold will be flagged and sent to the Software Architect for manual grading. This approach is chosen to leverage AI's speed and consistency while retaining human oversight for more complex or ambiguous answers.

## Consequences

- **Positive**:
  - Increased Efficiency: Significant reduction in grading time for a large number of responses.
  - Consistency: AI provides uniform grading criteria, reducing human-induced variability.
  - Immediate Feedback: Potential for providing students with quicker feedback on their performance.
  
- **Negative**:
  - Resource Intensive: Initial setup and maintenance of AI systems require time and investment.
  - Risk of Misgrading: There's a small risk of AI misgrading nuanced answers, though mitigated by the human review process.
  - Dependence on Technology: Over-reliance on AI might reduce human engagement with the material.
- **Neutral**:
  - Data Collection: This will provide a wealth of data for analysis, which could be used for future test development or educational research.


## Alternatives Considered

- Option 1:
  - Description: Continue with only manual grading for all short answer questions.
  - Reason for rejection: Manual grading alone would be too slow for our current scale and could lead to inconsistent grading due to human fatigue or bias.
- Option 2:
  - Description: Use AI for all grading without human intervention.
  - Reason for rejection: This approach risks errors in interpretation of nuanced or creative answers, potentially lowering the quality of grading.


## References

## Notes
The exact percentage (N%) for AI confidence will be determined through pilot testing to ensure accuracy and reliability.
This decision is subject to review based on feedback and performance metrics of the AI system in actual use.